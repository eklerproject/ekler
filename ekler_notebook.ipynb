{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#You don't need to run this code. It is the data we used. There are bunch of verbs.\n",
        "import requests\n",
        "file = requests.get(\"https://raw.githubusercontent.com/Loodos/zemberek-python/master/zemberek/resources/lexicon.csv\")\n",
        "\n",
        "\n",
        "lemma_list = sorted({line.split(\"\\t\")[2] for line in file.text.split(\"\\n\")[:-1] \n",
        "                     if line.split(\"\\t\")[2].isalpha() and \n",
        "                        (line.split(\"\\t\")[0].endswith(\"Verb\"))\n",
        "                        and len(line.split(\"\\t\")[2]) > 2\n",
        "                        })"
      ],
      "metadata": {
        "id": "fiO_PTp9rIIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#No need to run also.\n",
        "#Our good HFST has 8 lexicons, according to the last vowel of the verb and to the last character, if it is a consonant.\n",
        "#Lexicon 1 -> last vowel: \"a\" or \"ı\", last consonant: voiced\n",
        "#Lexicon 2 -> last vowel: \"a\" or \"ı\", last consonant: voiceless \n",
        "#(The correct numbering of lexicons is not like this. For example, Lexicon V1 is \"ü, ö\" and voiced. But to get the idea... Numbering of these lexicons was arbitrary. No one knows what Arif was thinking, even himself.)\n",
        "Verbs=lemma_list\n",
        "consonants_v=[\"b\",\"c\",\"d\",\"g\",\"ğ\",\"j\",\"l\",\"m\",\"n\",\"r\",\"v\",\"y\",\"z\"]\n",
        "consonant_vs=[\"ç\",\"f\",\"h\",\"k\",\"p\",\"s\",\"ş\",\"t\"]\n",
        "vowel1=[\"ö\",\"ü\"]\n",
        "vowel2=[\"a\",\"ı\"]\n",
        "vowel3=[\"u\",\"o\"]\n",
        "vowel4=[\"e\",\"i\"]\n",
        "vowel5= [\"ö\",\"ü\",\"a\",\"ı\",\"e\",\"u\",\"o\",\"i\"]\n",
        "#Code below deletes the final character if it is a vowel. Because we handled \"ünlü daralması\" with deleting the character if it is a vowel and intorducing \"-(v)yor\" with (v) = the correct vowel.\n",
        "for verb in Verbs:\n",
        "  if verb[-1] in vowel5:\n",
        "    verb=verb[:-1]\n",
        "    Verbs.append(verb)\n",
        "with open(\"lemma_list_for_good_hfst.lexc\",\"w\") as f: #opens a file\n",
        "  f.write(\"Verbs\\n\")\n",
        "  for verb in Verbs:\n",
        "    if verb[-1] in vowel1:  #if last character is ö or ü\n",
        "        f.write(\"\\t\"+verb+\"\\tV1;\\n\") #goes to Lexicon V1\n",
        "    if verb[-1] in vowel2:\n",
        "        f.write(\"\\t\"+verb+\"\\tV2;\\n\") #if a, ı goes to Lexicon V2 and goes on...\n",
        "    if verb[-1] in vowel3:\n",
        "        f.write(\"\\t\"+verb+\"\\tV3;\\n\")\n",
        "    if verb[-1] in vowel4:\n",
        "        f.write(\"\\t\"+verb+\"\\tV6;\\n\")\n",
        "    elif verb[-1] in consonants_v: #if last character is a consonant and voiced\n",
        "      if verb[-2] in consonants_v: #if second from the last is a consonant and voiced too,\n",
        "        if verb[-3] in vowel1:  #looks at the third from the last to find a vowel. Rest is the same, assigns to the correct lexicon\n",
        "          f.write(\"\\t\"+verb+\"\\tV1;\\n\")\n",
        "        if verb[-3] in vowel2:\n",
        "          f.write(\"\\t\"+verb+\"\\tV2;\\n\")\n",
        "        if verb[-3] in vowel3:\n",
        "          f.write(\"\\t\"+verb+\"\\tV3;\\n\")\n",
        "        if verb[-3] in vowel4:\n",
        "          f.write(\"\\t\"+verb+\"\\tV6;\\n\")\n",
        "\n",
        "      if verb[-2] in consonant_vs: #if second from the last is a consonant and voiceless\n",
        "        if verb[-3] in vowel1: #looks at the third, and same.\n",
        "          f.write(\"\\t\"+verb+\"\\tV1;\\n\")\n",
        "        if verb[-3] in vowel2:\n",
        "          f.write(\"\\t\"+verb+\"\\tV2;\\n\")\n",
        "        if verb[-3] in vowel3:\n",
        "          f.write(\"\\t\"+verb+\"\\tV3;\\n\")\n",
        "        if verb[-3] in vowel3:\n",
        "          f.write(\"\\t\"+verb+\"\\tV3;\\n\")\n",
        "        if verb[-3] in vowel4:\n",
        "          f.write(\"\\t\"+verb+\"\\tV6;\\n\")\n",
        "\n",
        "      if verb[-2] in vowel1: #if last vowel is consonant looks at the second from last to find a vowel.\n",
        "        f.write(\"\\t\"+verb+\"\\tV1;\\n\")\n",
        "      if verb[-2] in vowel2:\n",
        "        f.write(\"\\t\"+verb+\"\\tV2;\\n\")\n",
        "      if verb[-2] in vowel3:\n",
        "        f.write(\"\\t\"+verb+\"\\tV3;\\n\")\n",
        "      if verb[-2] in vowel4:\n",
        "        f.write(\"\\t\"+verb+\"\\tV6;\\n\")\n",
        "    elif verb[-1] in consonant_vs: #if last vowel is a consonant and voiceless.\n",
        "      if verb[-2] in vowel1: #assigns verbs to the voiceless lexicons.\n",
        "        f.write(\"\\t\"+verb+\"\\tV4;\\n\")\n",
        "      if verb[-2] in vowel2:\n",
        "        f.write(\"\\t\"+verb+\"\\tV5;\\n\")\n",
        "      if verb[-2] in vowel3:\n",
        "        f.write(\"\\t\"+verb+\"\\tV8;\\n\")\n",
        "      if verb[-2] in vowel4:\n",
        "        f.write(\"\\t\"+verb+\"\\tV7;\\n\")"
      ],
      "metadata": {
        "id": "47IyjzYJrIuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#No need to run this code.\n",
        "#This code below is exactly the same but it is for bad HFST, so it only assigns to one lexicon which is \"Lexicon V\"\n",
        "Verbs=lemma_list\n",
        "consonants_v=[\"b\",\"c\",\"d\",\"g\",\"ğ\",\"j\",\"l\",\"m\",\"n\",\"r\",\"v\",\"y\",\"z\"]\n",
        "consonant_vs=[\"ç\",\"f\",\"h\",\"k\",\"p\",\"s\",\"ş\",\"t\"]\n",
        "vowel1=[\"ö\",\"ü\"]\n",
        "vowel2=[\"a\",\"ı\"]\n",
        "vowel3=[\"u\",\"o\"]\n",
        "vowel4=[\"e\",\"i\"]\n",
        "vowel5= [\"ö\",\"ü\",\"a\",\"ı\",\"e\",\"u\",\"o\",\"i\"]\n",
        "for verb in Verbs:\n",
        "  if verb[-1] in vowel5:\n",
        "    verb=verb[:-1]\n",
        "    Verbs.append(verb)\n",
        "with open(\"lemma_list_for_bad_hfst.lexc\",\"w\") as f:\n",
        "  f.write(\"Verbs\\n\")\n",
        "  for verb in Verbs:\n",
        "    f.write(\"\\t\"+verb+\"\\tV;\\n\")"
      ],
      "metadata": {
        "id": "Qe-xjld_vp6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#No need to run this as well.\n",
        "#This is a short code that we used to generate bad suffix forms like \"-aceksinuz\" for bad HFST.\n",
        "vowels= [\"ö\",\"ü\",\"a\",\"ı\",\"e\",\"u\",\"o\",\"i\"]\n",
        "\n",
        "for v in vowels:\n",
        "  for v1 in vowels:\n",
        "    print(f\"\\t+Past_3pl:t{v}l{v1}r\\tV;\")"
      ],
      "metadata": {
        "id": "ms9FqRG2yGXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wqLfd9IkrkO",
        "outputId": "0ceb8996-28a6-44a4-f844-685035af0d1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hfst-dev\n",
            "  Downloading hfst_dev-3.15.0.10b0-cp37-cp37m-manylinux1_x86_64.whl (31.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 31.7 MB 1.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: hfst-dev\n",
            "Successfully installed hfst-dev-3.15.0.10b0\n"
          ]
        }
      ],
      "source": [
        "#Introducing HFST\n",
        "#Run this\n",
        "!pip install hfst-dev\n",
        "import hfst_dev\n",
        "from hfst_dev import compile_lexc_script, compile_lexc_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rN7EMSCpk9CL"
      },
      "outputs": [],
      "source": [
        "#Run this after uploading \"bad_hfst.lexc\" and \"good_hfst.lexc\"\n",
        "from hfst_dev import HfstTransducer\n",
        "generatorTR=compile_lexc_file(\"bad_hfst.lexc\")  #Because the HFST we wrote has more than 12k lines, we introduce the HFST as a file.\n",
        "GeneratorTR_iyi =compile_lexc_file(\"good_hfst.lexc\")\n",
        "\n",
        "analyzer = HfstTransducer(generatorTR)  #Introducing HFST analyzer, we take the output thanks to this code.\n",
        "analyzer.invert()\n",
        "analyzer.minimize()\n",
        "\n",
        "\n",
        "\n",
        "analyzer1 = HfstTransducer(GeneratorTR_iyi) #Good HFST analyzer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GE2ccto3lh35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a921d16-e088-4035-9f9c-2c28adbc6c51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kelimenizi girin: geleyor\n",
            "Here is the correct spelling: geliyor\n"
          ]
        }
      ],
      "source": [
        "#This is the magic. Run this and write your word.\n",
        "input = input(\"Kelimenizi girin: \") #Input\n",
        "gorgor = analyzer.lookup(input)   #Takes the input at puts it into the bad HFST as an input\n",
        "\n",
        "out=gorgor[0][0]    #HFST gives the output as an array. Something like this -> ((gelirler, 00)). We get rid of parentheses and take only the actual output\n",
        "\n",
        "ek_list=out.split('+')[0:] #The suffixes are seperated with \"+\" we also get rid of these because \"+\" makes it harder to sort the suffixes in the following code.\n",
        "\n",
        "vowels = [\"ö\",\"ü\",\"a\",\"ı\",\"e\",\"u\",\"o\",\"i\"] #Introducing vowels\n",
        "\n",
        "#The code below gets everything in the correct order. In case there is a suffix wrongly placed, this code places it in the correct position.\n",
        "order_list={\"Neg\":1,\"Neg1\":1,\"Aorist_c\":2,\"Aorist_v\":2,\"Aorist_Neg\":2,\"Aorist_c_1sg\":2,\"Aorist_c_2sg\":2,\"Aorist_c_1pl\":2,\"Aorist_c_2pl\":2,\"Aorist_c_3pl\":2,\n",
        "            \"Aorist_v_1sg\":2,\"Aorist_v_2sg\":2,\"Aorist_v_1pl\":2,\"Aorist_v_2pl\":2,\"Aorist_v_3pl\":2,\n",
        "            \"Aorist_Neg1sg\":2,\"Aorist_Neg2sg\":2,\"Aorist_Neg3sg\":2,\"Aorist_Neg1pl\":2,\"Aorist_Neg2pl\":2,\"Aorist_Neg3pl\":2,\n",
        "            \"Prog\":2,\n",
        "            \"Prog_1sg\":2,\"Prog_2sg\":2,\"Prog_1pl\":2,\"Prog_2pl\":2,\"Prog_3pl\":2,\n",
        "            \"Future_c\":3,\"Future_v\":3,\n",
        "            \"Future_c_1sg\":3,\"Future_c_2sg\":3,\"Future_c_1pl\":3,\"Future_c_2pl\":3,\"Future_c_3pl\":3,\n",
        "            \"Future_v_1sg\":3,\"Future_v_2sg\":3,\"Future_v_1pl\":3,\"Future_v_2pl\":3,\"Future_v_3pl\":3,\n",
        "            \"Past_Ev\":4,\"Past\":5,\"Past1\":5,\n",
        "            \"Past_Ev_1sg\":4,\"Past_Ev_2sg\":4,\"Past_Ev_1pl\":4,\"Past_Ev_2pl\":4,\"Past_Ev_3pl\":4,\n",
        "            \"Past_1sg\":5,\"Past_2sg\":5,\"Past_1pl\":5,\"Past_2pl\":5,\"Past_3pl\":5\n",
        "            }\n",
        "\n",
        "if \"+Prog\" in out:\n",
        "  if ek_list[0][-1] in vowels:\n",
        "    ek_list[0] = ek_list[0][:-1]  #We handled \"ünlü daralması\" by deleting the last vowel, if any, in the word and introducing \"+Prog\" with the correct vowel.\n",
        "#So, our HFST does not have a \"-yor\" suffix only \"-iyor\", \"-ıyor\" etc. When +Prog placed wrongly, our HFST does not delete the last vowel of the word. \n",
        "#The code above makes sure the last vowel is deleted when \"+Prog\" is introduced\n",
        "\n",
        "#Correct ordering of suffixes by using \".sort\" function.\n",
        "new_order=[]\n",
        "for elt in ek_list[1:]:\n",
        "  new_order.append((order_list[elt],elt))\n",
        "new_order.sort()\n",
        "corrected_string=ek_list[0]\n",
        "#Introducing \"+\" again because we deleted it before.\n",
        "for ek in new_order:\n",
        "  corrected_string=corrected_string+\"+\"+ek[1]\n",
        "\n",
        "\n",
        "gargar = analyzer1.lookup(corrected_string) #Good HFST analyzer.\n",
        "\n",
        "#The output. If the input matches the final output, it gives a \"this is correct\" message. If it is not, gives the correct form.\n",
        "if input == gargar[0][0]:\n",
        "  print(\"Good Job!\")\n",
        "else:\n",
        "  print(f\"Here is the correct spelling: {gargar[0][0]}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ekler_notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}